{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.models.inception import inception_v3\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm_notebook\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "\n",
    "from model import AdvProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pimg_size = (224,224)\n",
    "img_size = (28,28)\n",
    "mask_size = pimg_size\n",
    "num_channels = 3\n",
    "\n",
    "model_name = 'resnet50'\n",
    "log_interval = 10\n",
    "\n",
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "data_dir = 'data/'\n",
    "models_dir = 'models/'\n",
    "logs_dir = 'logs/'\n",
    "train_ratio = 0.9\n",
    "\n",
    "writer = SummaryWriter(\"{}{}-{}\".format(logs_dir, model_name, time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pad = int((pimg_size[0]-img_size[0]+1)/2)\n",
    "r_pad = int((pimg_size[0]-img_size[0])/2)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(padding=(l_pad, l_pad, r_pad, r_pad)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.cat([x]*3)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(data_dir, train=True, transform=transform, download=True)\n",
    "# dataset_size = 10000\n",
    "# train_dataset, valid_dataset, _ = random_split(dataset, [int(train_ratio*dataset_size), dataset_size - int(train_ratio*dataset_size), len(dataset) - dataset_size])\n",
    "train_dataset, valid_dataset = random_split(dataset, [int(train_ratio*len(dataset)), len(dataset) - int(train_ratio*len(dataset))])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(data_dir, train=False, transform=transform),\n",
    "    batch_size=test_batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = resnet50(pretrained=True).to(device)\n",
    "model.eval()\n",
    "print(len([1 for param in model.parameters() if param.requires_grad]))\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(len([1 for param in model.parameters() if param.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = AdvProgram(img_size, pimg_size, mask_size, normalization='imagenet', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pr.program.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = torch.rand(num_channels, *pimg_size, device=device)\n",
    "program.requires_grad = True\n",
    "\n",
    "l_pad = int((mask_size[0]-img_size[0]+1)/2)\n",
    "r_pad = int((mask_size[0]-img_size[0])/2)\n",
    "\n",
    "mask = torch.zeros(num_channels, *img_size, device=device)\n",
    "mask = F.pad(mask, (l_pad, r_pad, l_pad, r_pad), value=1)\n",
    "\n",
    "optimizer = optim.Adam([program], lr=0.05, weight_decay=0.00)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.96)\n",
    "\n",
    "loss_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(mode, data_loader, num_classes=10, optimizer=None, epoch=None, steps_per_epoch=None, loss_criterion=None):\n",
    "    if mode == 'train':\n",
    "        program.requires_grad = True\n",
    "    else:\n",
    "        program.requires_grad = False\n",
    "\n",
    "    loss = 0.0\n",
    "    if mode != 'train':\n",
    "        y_true = None\n",
    "        y_pred = None\n",
    "\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(data_loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        ite = tqdm_notebook(\n",
    "            enumerate(data_loader, 0),\n",
    "            total=steps_per_epoch,\n",
    "            desc='Epoch {}: '.format(epoch)\n",
    "        )\n",
    "    else:\n",
    "        ite = tqdm_notebook(enumerate(data_loader, 0))\n",
    "\n",
    "    for i, data in ite:\n",
    "        x = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if mode == 'train':\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if mode != 'train':\n",
    "            with torch.no_grad():\n",
    "                x = x + F.tanh(program*mask)\n",
    "                logits = model(x)\n",
    "        else:\n",
    "            x = x + torch.tanh(program*mask)\n",
    "            logits = model(x)\n",
    "\n",
    "        logits = logits[:,:num_classes]\n",
    "\n",
    "        if loss_criterion is not None:\n",
    "            batch_loss = loss_criterion(logits, y)\n",
    "\n",
    "            if mode == 'train':\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            loss += batch_loss.item()\n",
    "\n",
    "        if mode != 'train':\n",
    "            if y_true is None:\n",
    "                y_true = y\n",
    "            else:\n",
    "                y_true = torch.cat([y_true, y], dim=0)\n",
    "\n",
    "            if y_pred is None:\n",
    "                y_pred = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
    "            else:\n",
    "                y_pred = torch.cat([y_pred, torch.argmax(torch.softmax(logits, dim=1), dim=1)], dim=0)\n",
    "\n",
    "            error_rate = torch.sum(y_true!=y_pred).item()/(y_true.shape[0])\n",
    "\n",
    "        if i % log_interval == 0:\n",
    "            writer.add_scalar(\"{}_loss\".format(mode), loss/(i+1), epoch*steps_per_epoch + i)\n",
    "            if mode != 'train':\n",
    "                writer.add_scalar(\"{}_error_rate\".format(mode), error_rate, epoch*steps_per_epoch + i)\n",
    "\n",
    "            print(\"\\rLoss at Step {} : {}\".format(epoch*steps_per_epoch + i, loss/(i+1)), end='')\n",
    "\n",
    "        if i >= steps_per_epoch:\n",
    "            break\n",
    "\n",
    "    if mode != 'train':\n",
    "        return loss/steps_per_epoch, {'error_rate': error_rate}\n",
    "    return loss/steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "best_error_rate = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lr_scheduler.step()\n",
    "    train_loss = run_epoch('train', train_loader, 10, optimizer, epoch=epoch, loss_criterion=loss_criterion)\n",
    "    valid_loss, val_metrics = run_epoch('valid', valid_loader, 10, epoch=epoch, loss_criterion=loss_criterion)\n",
    "    error_rate = val_metrics['error_rate']\n",
    "    if error_rate < best_error_rate:\n",
    "        torch.save({'program':program, 'mask':mask}, \"{}{}.pt\".format(models_dir, model_name))\n",
    "        best_error_rate = error_rate\n",
    "\n",
    "    _, test_metrics = run_epoch('test', test_loader, 10, epoch=epoch)\n",
    "    \n",
    "    print('\\rTrain loss : {}, Validation Loss : {}, Validation_ER : {}, Test Metrics : {}'.format(train_loss, valid_loss, error_rate, str(test_metrics)), end='')\n",
    "#     imshow(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('models/resnet50.pt')\n",
    "program = state['program']\n",
    "mask = state['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(program.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    return transforms.ToPILImage()(img.detach().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
